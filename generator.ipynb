{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mRNA data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_raw=pd.read_csv('TCGA_inter_SNUH_clinical_standardized_combat_quantile_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_raw=mrna_raw.iloc[:-70,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-coding RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnc_raw=pd.read_csv(\"TCGA_inter_SNUH_clinical_lnc_standardized_combat_quantile_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnc_raw=lnc_raw.iloc[:-70,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Survival patients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "survival_raw=pd.read_csv(\"TCGA_OV_survival_reference.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vital status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vital_raw=pd.read_csv('balanced_index_230.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_raw=mrna_raw.dropna()\n",
    "lnc_raw=lnc_raw.dropna()\n",
    "survival_raw=survival_raw.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_raw=mrna_raw.drop_duplicates()\n",
    "lnc_raw=lnc_raw.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n",
      "426\n"
     ]
    }
   ],
   "source": [
    "mrna_patient_idx=mrna_raw.patient.values\n",
    "lnc_patient_idx=lnc_raw.patient.values\n",
    "print(len(mrna_patient_idx))\n",
    "print(len(lnc_patient_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(426, 22205)\n",
      "(426, 1886)\n",
      "(485, 2)\n"
     ]
    }
   ],
   "source": [
    "print(mrna_raw.shape)\n",
    "print(lnc_raw.shape)\n",
    "print(survival_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check an existance of lnc data in mrna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(426, 22205)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrna_raw.loc[mrna_raw.patient.isin(lnc_patient_idx)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract existed idx from survival raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "existed_survival=survival_raw.loc[survival_raw.patient.isin(lnc_patient_idx),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "408"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(existed_survival)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_col=mrna_raw.columns.values\n",
    "lnc_col=lnc_raw.columns.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove 'Patients' columns in lnc_col\n",
    "lnc_col=lnc_col[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_col=[]\n",
    "for i in mrna_col:\n",
    "    if i in lnc_col:\n",
    "        intersection_col.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete overlapped columns in mrna data\n",
    "del_inter_mrna_raw=mrna_raw.drop(columns=intersection_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mrna=del_inter_mrna_raw.loc[del_inter_mrna_raw.patient.isin(existed_survival.patient.values),:]\n",
    "test_lnc=lnc_raw.loc[lnc_raw.patient.isin(existed_survival.patient.values),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n",
      "426\n",
      "413\n",
      "413\n"
     ]
    }
   ],
   "source": [
    "print(len(del_inter_mrna_raw))\n",
    "print(len(lnc_raw))\n",
    "print(len(test_mrna))\n",
    "print(len(test_lnc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Delete duplicated patients id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete duplicated patients id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_inter_mrna_raw=del_inter_mrna_raw.drop_duplicates(subset='patient')\n",
    "lnc_raw=lnc_raw.drop_duplicates(subset='patient')\n",
    "test_lnc=test_lnc.drop_duplicates(subset='patient')\n",
    "test_mrna=test_mrna.drop_duplicates(subset='patient')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lnc_data=pd.merge(test_lnc,existed_survival,on=['patient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_data=pd.merge(test_mrna,existed_survival,on=['patient'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#find row of containing null value\n",
    "tmp[tmp.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "\n",
    "from itertools import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highway net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Highway(nn.Module):\n",
    "    def __init__(self,size,num_layers,f):\n",
    "        super().__init__()\n",
    "        self.num_layers=num_layers\n",
    "        self.nonlinear=nn.ModuleList([nn.Linear(size,size) for _ in range(num_layers)])\n",
    "        self.linear=nn.ModuleList([nn.Linear(size,size) for _ in range(num_layers)])\n",
    "        self.gate=nn.ModuleList([nn.Linear(size,size) for _ in range(num_layers)])\n",
    "        self.f=f\n",
    "    def forward(self,x):\n",
    "        for layer in range(self.num_layers):\n",
    "            gate=F.sigmoid(self.gate[layer](x))\n",
    "            nonlinear=self.f(self.nonlinear[layer](x))\n",
    "            linear=self.linear[layer](x)\n",
    "            x=gate*nonlinear+(1-gate)*linear\n",
    "        return x\n",
    "                       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity_loss(modalities):\n",
    "    mode_rna=modalities['rna'].detach()\n",
    "    #print(f'mode_rna:{mode_rna.shape}')\n",
    "    #print(mode_rna[0,:])\n",
    "    mode_lnc=modalities['lnc'].detach()\n",
    "    #print(f'mode_lnc:{mode_lnc.shape}')\n",
    "    cos=nn.CosineSimilarity(dim=1,eps=1e-6)\n",
    "    M=0.1\n",
    "    N=mode_rna.shape[0]\n",
    "    loss=[]\n",
    "    #sim(x,x) output=distance of num of samples\n",
    "    sim_same=cos(mode_rna,mode_lnc)\n",
    "    avg_sim_same=torch.sum(sim_same)/N\n",
    "    tmp=torch.clone(mode_lnc[0,:])\n",
    "    mode_lnc[0:-1,:]=mode_lnc[1:,:]\n",
    "    mode_lnc[-1,:]=tmp\n",
    "    #print(mode_rna.shape[0]-1)\n",
    "    for i in range(mode_rna.shape[0]-1):\n",
    "        #sim(x,y) output=distance of num of samples\n",
    "        sim_diff=cos(mode_rna,mode_lnc)\n",
    "        #print(f'sim diff :{sim_diff}')\n",
    "        avg_sim_diff=torch.sum(sim_diff)/N\n",
    "        #L_theta(x,y)=max(M-sim(x,y)+sim(x,x))\n",
    "        L_theta_x_y=max(0,M-avg_sim_diff+avg_sim_same)\n",
    "        loss.append(L_theta_x_y)\n",
    "        #print(L_theta_x_y)\n",
    "        #shift y data\n",
    "        tmp=torch.clone(mode_lnc[0,:])\n",
    "        mode_lnc[0:-1,:]=mode_lnc[1:,:]\n",
    "        mode_lnc[-1,:]=tmp\n",
    "    total_loss=sum(loss)/len(loss)\n",
    "    return total_loss\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fcm=nn.Linear(20319,256)\n",
    "        self.fcl=nn.Linear(1885,256)\n",
    "        self.highway=Highway(256,10,f=F.relu)\n",
    "        self.fc2=nn.Linear(512,2)\n",
    "        self.fcd=nn.Linear(512,1)\n",
    "        self.bn1=nn.BatchNorm1d(256)\n",
    "        self.bn2=nn.BatchNorm1d(256)\n",
    "        self.bn3=nn.BatchNorm1d(1)\n",
    "    \n",
    "    def forward(self,data):\n",
    "        x=data['mRNA']\n",
    "        #print(x)\n",
    "        x=x.view(x.shape[0],-1)\n",
    "        x=F.dropout(x,0.4)\n",
    "        x=F.tanh(self.fcm(x))\n",
    "        x=self.bn1(x)\n",
    "        x=F.dropout(x,0.5,training=self.training)\n",
    "        x=self.highway(x)\n",
    "        x=self.bn2(x)\n",
    "        \n",
    "        y=data['lnc']\n",
    "        #print(y)\n",
    "        y=y.view(y.shape[0],-1)        \n",
    "        y=F.dropout(y,0.4)\n",
    "        y=F.tanh(self.fcl(y))\n",
    "        y=self.bn1(y)\n",
    "        y=F.dropout(y,0.5,training=self.training)\n",
    "        y=self.highway(y)\n",
    "        y=self.bn2(y)\n",
    "        \n",
    "        modal={'rna':x.clone(),'lnc':y.clone()}\n",
    "        #similarity loss\n",
    "        sim_loss=Similarity_loss(modal)\n",
    "        #print(sim_loss.requires_grad)\n",
    "        #concatenates x and y\n",
    "        concat_x_y=torch.cat((x,y),1)\n",
    "        \n",
    "        #vital status\n",
    "        #score=F.log_softmax(self.fc2(concat_x_y),dim=1)\n",
    "        #survival\n",
    "        hazard=self.fcd(concat_x_y)\n",
    "        \n",
    "        #print(f'hazard:{hazard}type:{hazard.requires_grad}')\n",
    "        return {'sim_loss':sim_loss,'hazard':hazard}\n",
    "    def loss(self,pred,target):\n",
    "        \n",
    "        days_to_death=target\n",
    "        hazard=pred['hazard'].squeeze()\n",
    "        \n",
    "        _,idx=torch.sort(days_to_death)\n",
    "        hazard_probs=F.softmax(hazard[idx].squeeze())\n",
    "        hazard_cum=torch.stack([torch.tensor(0.0)]+list(accumulate(hazard_probs)))\n",
    "        N=hazard_probs.shape[0]\n",
    "        weights_cum=torch.range(1,N)\n",
    "        p,q=hazard_cum[1:],1-hazard_cum[:-1]\n",
    "        \n",
    "        w1,w2=weights_cum,N-weights_cum\n",
    "        probs=torch.stack([p,q],dim=1)\n",
    "        logits=torch.log(probs)\n",
    "        ll1 = (F.nll_loss(logits, torch.zeros(N).long(), reduce=False) * w1)/N\n",
    "        ll2 = (F.nll_loss(logits, torch.ones(N).long(), reduce=False) * w2)/N\n",
    "        loss2 = torch.mean(ll1 + ll2)\n",
    "        \n",
    "        \n",
    "        loss1=pred['sim_loss']\n",
    "        \n",
    "        return loss1+loss2\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split 98/2 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrna_train,mrna_test=train_test_split(mrna_data,test_size=0.02,random_state=777)\n",
    "lnc_train,lnc_test=train_test_split(lnc_data,test_size=0.02,random_state=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 20321)\n",
      "(9, 1887)\n"
     ]
    }
   ],
   "source": [
    "print(mrna_train.shape)\n",
    "print(lnc_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_data={'mRNA':mrna_train.iloc[:,1:].to_numpy(),'lnc':lnc_train.iloc[:,1:].to_numpy()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset,DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateData(Dataset):\n",
    "    def __init__(self,dataset):\n",
    "        mrna_data=dataset['mRNA']\n",
    "        lnc_data=dataset['lnc']\n",
    "        self.len=mrna_data.shape[0]\n",
    "        self.rna_x=torch.from_numpy(mrna_data[:,0:-1]).float()\n",
    "        self.rna_y=torch.from_numpy(mrna_data[:,-1]).float()\n",
    "        self.lnc_x=torch.from_numpy(lnc_data[:,0:-1]).float()\n",
    "        self.lnc_y=torch.from_numpy(lnc_data[:,-1]).float()\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "        data={'mRNA':self.rna_x[index],'lnc':self.lnc_x[index],'mRNA_y':self.rna_y[index],'lnc_y':self.lnc_y[index]}\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=GenerateData(whole_data)\n",
    "train_loader=DataLoader(dataset=dataset,batch_size=16,shuffle=False,num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if use_cuda else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiNet(\n",
       "  (fcm): Linear(in_features=20319, out_features=256, bias=True)\n",
       "  (fcl): Linear(in_features=1885, out_features=256, bias=True)\n",
       "  (highway): Highway(\n",
       "    (nonlinear): ModuleList(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (7): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (8): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (9): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear): ModuleList(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (7): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (8): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (9): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (gate): ModuleList(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (4): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (5): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (7): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (8): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (9): Linear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (fc2): Linear(in_features=512, out_features=2, bias=True)\n",
       "  (fcd): Linear(in_features=512, out_features=1, bias=True)\n",
       "  (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (bn3): BatchNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=MultiNet()\n",
    "model.cpu()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "use_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-4\n",
    "optimizer=optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of i :0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/learnmore/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:55: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/learnmore/anaconda3/envs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:58: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of i :1\n",
      "# of i :2\n",
      "# of i :3\n",
      "# of i :4\n",
      "# of i :5\n",
      "# of i :6\n",
      "# of i :7\n",
      "# of i :8\n",
      "# of i :9\n",
      "# of i :10\n",
      "# of i :11\n",
      "# of i :12\n",
      "# of i :13\n",
      "# of i :14\n",
      "# of i :15\n",
      "# of i :16\n",
      "# of i :17\n",
      "# of i :18\n",
      "# of i :19\n",
      "# of i :20\n",
      "# of i :21\n",
      "# of i :22\n",
      "# of i :23\n",
      "# of i :24\n"
     ]
    }
   ],
   "source": [
    "for i,data in enumerate(train_loader):\n",
    "    print(f'# of i :{i}')\n",
    "    with torch.autograd.set_detect_anomaly(True):\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        loss=model.loss(output,data['mRNA_y'])\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train,Test split 99/1\n",
    "#Generate Instance\n",
    "#Train\n",
    "#Optim_zero_grad\n",
    "#Loss\n",
    "#Backward\n",
    "#Optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
